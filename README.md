# YManga

DATA of PAPER -> Exploring the Capability of Multimodal LLMs with Yonkoma Manga: The YManga dataset and Its Challenging Tasks

TO: https://github.com/DUTIR-Emotion-Group/CCAC2025-task3

CITE:
  @inproceedings{ymanga,
    author       = {Qi Yang and
                    Jingjie Zeng and
                    Liang Yang and
                    Zhihao Yang and
                    Hongfei Lin},
    editor       = {Yaser Al{-}Onaizan and
                    Mohit Bansal and
                    Yun{-}Nung Chen},
    title        = {Exploring the Capability of Multimodal LLMs with Yonkoma Manga: The
                    YManga Dataset and Its Challenging Tasks},
    booktitle    = {Findings of the Association for Computational Linguistics: {EMNLP}
                    2024, Miami, Florida, USA, November 12-16, 2024},
    pages        = {8672--8687},
    publisher    = {Association for Computational Linguistics},
    year         = {2024},
    url          = {https://aclanthology.org/2024.findings-emnlp.506},
    timestamp    = {Mon, 18 Nov 2024 09:05:59 +0100},
    biburl       = {https://dblp.org/rec/conf/emnlp/YangZ0YL24.bib},
    bibsource    = {dblp computer science bibliography, https://dblp.org}
  }
